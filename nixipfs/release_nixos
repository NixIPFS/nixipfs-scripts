#!/usr/bin/env python
import sys
import argparse
import os
import shutil
import json
import jsonschema
import time
import datetime
from nixipfs.create_channel_release import create_channel_release
from nixipfs.create_nixipfs import create_nixipfs
from nixipfs.garbage_collect import garbage_collect
from nixipfs.update_binary_cache import update_binary_cache
from nixipfs.mirror_tarballs import mirror_tarballs
from nixipfs.nix_helpers import NarInfo
from glob import glob

config_schema = {
    "$schema": "http://json-schema.org/schema#",
    "type" : "object",
    "required" : ["hydra", "cache", "target_cache", "releases", "repo" ],
    "properties": {
        "hydra": {"type": "string", "format": "uri"},
        "cache": {"type": "string", "format": "uri"},
        "target_cache": {"type": "string"},
        "repo": {"type": "string"},
        "max_threads": {"type": "integer"},
        "max_ipfs_threads": {"type": "integer"},
        "releases": {"type": "array",
                     "items": {
                         "type": "object",
                         "required" : [ "channel", "project", "jobset" ],
                         "properties" : {
                             "channel": {"type": "string"},
                             "project": {"type": "string"},
                             "jobset" : {"type": "string"},
                             "job"    : {"type": "string"},
                             "keep"   : {"type": "integer", "minimum": 1},
                             "mirror"   : {"type": "boolean"}
                         }
                     }
        }
    }
}

def release_nixos(outdir, tmpdir, ipfsapi, print_only, no_ipfs, gc, config):
    releases = config["releases"]
    hydra = config["hydra"]
    cache = config["cache"]
    target_cache = config["target_cache"]
    max_threads = config.get("max_threads", 7)

    cache_info = {'StoreDir' : '/nix/store', 'WantMassQuery' : '1', 'Priority' : '40' }

    paths = []
    binary_cache_dir  = os.path.join(outdir, 'binary_cache')
    channel_dir = os.path.join(outdir, 'channels')
    releases_dir = os.path.join(outdir, 'releases')
    mirror_dir = os.path.join(outdir, 'tarballs')
    lastsync_file = os.path.join(outdir, 'lastsync')
    os.makedirs(channel_dir, exist_ok=True)
    os.makedirs(releases_dir, exist_ok=True)

    for release in releases:
        path = create_channel_release(channel = release['channel'],
                                      hydra   = hydra,
                                      project = release['project'],
                                      jobset  = release['jobset'],
                                      job     = release['job'],
                                      cache   = cache,
                                      outdir  = releases_dir,
                                      tmpdir  = tmpdir,
                                      target_cache = target_cache)
        if not len(path):
            print("Could not release {}".format(release))
            sys.exit()
        else:
            paths.append(path)
        update_binary_cache(cache, path, outdir, max_threads, print_only, cache_info)
        channel_link = os.path.join(channel_dir, release['channel'])
        if os.path.islink(channel_link):
            os.unlink(channel_link)
        os.symlink(os.path.join("../releases", release['channel'], os.path.basename(path)), channel_link)
        if release['mirror'] == True:
            with open(os.path.join(path, "git-revision"), 'r') as f:
                revision = f.read().strip()
            mirror_tarballs(mirror_dir, tmpdir, config["repo"], revision, max_threads)

    if not os.path.isfile(os.path.join(binary_cache_dir, 'nix-cache-info')):
        nci = NarInfo()
        nci.d = cache_info
        with open(os.path.join(binary_cache_dir, 'nix-cache-info'), 'w') as f:
            f.write(nci.to_string())

    if gc:
        for release in releases:
            if "keep" in release:
                release_dirs = [ e.rstrip('/') for e in glob(os.path.join(releases_dir, release['channel']) + '/*/')]
                release_dirs.sort(key=lambda x: os.stat(x).st_ctime)
                # keep the newest release(s):
                for x in release_dirs[:-release["keep"]]:
                    print("Deleting {}".format(x))
                    shutil.rmtree(x)

        release_dirs = []
        for release_name in [ e.rstrip('/') for e in glob(releases_dir + '/*/')]:
            for release_dir in [ e.rstrip('/') for e in glob(release_name + '/*/')]:
                release_dirs.append(release_dir)
        garbage_collect(binary_cache_dir, release_dirs)

    if not (print_only or no_ipfs):
        create_nixipfs(outdir, ipfsapi)

    with open(lastsync_file, 'w') as f:
        f.write("{},{}".format(int(time.time()), datetime.datetime.now().isoformat()))

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Release all the things! (NixOS)')
    parser.add_argument('--ipfsapi', default=('127.0.0.1', 5001), nargs=2, metavar="IP PORT")
    parser.add_argument('--dir', required=True)
    parser.add_argument('--tmpdir', required=True)
    parser.add_argument('--print_only', action='store_true')
    parser.add_argument('--gc', action='store_true')
    parser.add_argument('--no_ipfs', action='store_true')
    parser.add_argument('--config', required=True)
    args = parser.parse_args()

    # Check schema first
    jsonschema.Draft4Validator.check_schema(config_schema)

    with open(args.config, "r") as f:
        config = json.load(f)
    jsonschema.Draft4Validator(config_schema).validate(config)
    release_nixos(outdir=args.dir, tmpdir=args.tmpdir, ipfsapi=args.ipfsapi, print_only=args.print_only, no_ipfs=args.no_ipfs, gc=args.gc, config=config)
